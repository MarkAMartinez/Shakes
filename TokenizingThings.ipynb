{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import parse_corpus\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"preprocessed_shakespeare.txt\"\n",
    "\n",
    "sections = parse_corpus.process(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(\"/Users/markmartinez/Desktop/shakespeare.txt\",\"r\") as F:\n",
    "#     allText = F.read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stopwords, tokenize, stem (takes about 30 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rousillon the count palac enter bertram countess of rousillon helena lafeu black countess in deliv son me i buri second husband bertram and i go madam weep father death anew i must attend majesti command i ward evermor subject lafeu you shall find king husband madam you sir father he gener time good must necess hold virtu you whose worthi would stir want rather lack abund countess what hope majesti amend lafeu he hath abandon physician madam whose practic hath persecut time hope find advantag pr\n"
     ]
    }
   ],
   "source": [
    "stops = stopwords.words(\"english\")\n",
    "stopdict = dict((s,None) for s in stops) # Sets are really terrible in Python\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "clean_sections = []\n",
    "\n",
    "# NOTE(tfs): I am using tokenization now. Mainly it really cleans up punctuation and handles contractions well\n",
    "for section in sections:\n",
    "    secwords = section.split()\n",
    "    nonstops = [w.lower() for w in secwords if not w in stopdict]\n",
    "    tokens = nltk.word_tokenize(\" \".join(nonstops))\n",
    "    clean_sections.append(\" \".join([ps.stem(t) for t in tokens if t.isalnum()])) # Note this does not preserve structure,\n",
    "                                              #      but all words are now present in the section string\n",
    "print clean_sections[0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stops = set(stopwords.words(\"english\"))\n",
    "# words = allText.split()\n",
    "# meaningful_words = [w for w in words if not w in stops]\n",
    "# cleanedUp =  \" \".join( meaningful_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanedUp[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now split on 'scene'\n",
    "# scenes = [x.strip() for x in cleanedUp.split(\"scene\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\")\n",
    "\n",
    "data = vectorizer.fit_transform(clean_sections)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print sum(train_data_features[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = vectorizer.get_feature_names()\n",
    "# print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Sum up the counts of each vocabulary word\n",
    "# dist = np.sum(data, axis=0)\n",
    "\n",
    "# # For each, print the vocabulary word and the number of times it \n",
    "# # appears in the training set\n",
    "# for tag, count in zip(vocab, dist):\n",
    "#     print(count, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Run LDA (takes a bit of time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "num_topics = 20\n",
    "num_iter = 500\n",
    "n_top_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 643\n",
      "INFO:lda:vocab_size: 13409\n",
      "INFO:lda:n_words: 466303\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 500\n",
      "INFO:lda:<0> log likelihood: -5204287\n",
      "INFO:lda:<10> log likelihood: -4232255\n",
      "INFO:lda:<20> log likelihood: -4061967\n",
      "INFO:lda:<30> log likelihood: -3989114\n",
      "INFO:lda:<40> log likelihood: -3942837\n",
      "INFO:lda:<50> log likelihood: -3904528\n",
      "INFO:lda:<60> log likelihood: -3876797\n",
      "INFO:lda:<70> log likelihood: -3851616\n",
      "INFO:lda:<80> log likelihood: -3827616\n",
      "INFO:lda:<90> log likelihood: -3803176\n",
      "INFO:lda:<100> log likelihood: -3781590\n",
      "INFO:lda:<110> log likelihood: -3766195\n",
      "INFO:lda:<120> log likelihood: -3752205\n",
      "INFO:lda:<130> log likelihood: -3736597\n",
      "INFO:lda:<140> log likelihood: -3725179\n",
      "INFO:lda:<150> log likelihood: -3715526\n",
      "INFO:lda:<160> log likelihood: -3703483\n",
      "INFO:lda:<170> log likelihood: -3695325\n",
      "INFO:lda:<180> log likelihood: -3687659\n",
      "INFO:lda:<190> log likelihood: -3682436\n",
      "INFO:lda:<200> log likelihood: -3673757\n",
      "INFO:lda:<210> log likelihood: -3669990\n",
      "INFO:lda:<220> log likelihood: -3666163\n",
      "INFO:lda:<230> log likelihood: -3660670\n",
      "INFO:lda:<240> log likelihood: -3659423\n",
      "INFO:lda:<250> log likelihood: -3654028\n",
      "INFO:lda:<260> log likelihood: -3650292\n",
      "INFO:lda:<270> log likelihood: -3647076\n",
      "INFO:lda:<280> log likelihood: -3643771\n",
      "INFO:lda:<290> log likelihood: -3640318\n",
      "INFO:lda:<300> log likelihood: -3638841\n",
      "INFO:lda:<310> log likelihood: -3635679\n",
      "INFO:lda:<320> log likelihood: -3633998\n",
      "INFO:lda:<330> log likelihood: -3633903\n",
      "INFO:lda:<340> log likelihood: -3630747\n",
      "INFO:lda:<350> log likelihood: -3629593\n",
      "INFO:lda:<360> log likelihood: -3629702\n",
      "INFO:lda:<370> log likelihood: -3629746\n",
      "INFO:lda:<380> log likelihood: -3628724\n",
      "INFO:lda:<390> log likelihood: -3625629\n",
      "INFO:lda:<400> log likelihood: -3626460\n",
      "INFO:lda:<410> log likelihood: -3623845\n",
      "INFO:lda:<420> log likelihood: -3623200\n",
      "INFO:lda:<430> log likelihood: -3621956\n",
      "INFO:lda:<440> log likelihood: -3621621\n",
      "INFO:lda:<450> log likelihood: -3620521\n",
      "INFO:lda:<460> log likelihood: -3620400\n",
      "INFO:lda:<470> log likelihood: -3617999\n",
      "INFO:lda:<480> log likelihood: -3617208\n",
      "INFO:lda:<490> log likelihood: -3616902\n",
      "INFO:lda:<499> log likelihood: -3617485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: soldier enter franc us the shall lord talbot fight french\n",
      "Topic 1: you to lord the love that shall one it thi\n",
      "Topic 2: macbeth prospero macduff sebastian the ariel antonio stephano ladi banquo\n",
      "Topic 3: come what well say he good man is would enter\n",
      "Topic 4: brutu caesar citizen cassiu coriolanu meneniu rome you first marciu\n",
      "Topic 5: helena parol love bertram and lafeu demetriu lysand hermia bottom\n",
      "Topic 6: and the to that may for but heart like hand\n",
      "Topic 7: troilu hector pandaru cressida achil thersit ajax ulyss agamemnon diomed\n",
      "Topic 8: king franc berown princess of armado john costard bastard katharin\n",
      "Topic 9: of iago othello cassio syracus desdemona dromio antipholu imogen ephesu\n",
      "Topic 10: titu and portia luciu marcu bassanio rome antonio shylock aaron\n",
      "Topic 11: valentin and proteu petruchio sir love julia speed tranio lucentio\n",
      "Topic 12: lord timon second servant apemantu posthumu iachimo third senat men\n",
      "Topic 13: duke angelo isabella claudio provost brother sir lucio pedro bene\n",
      "Topic 14: thou thi thee art death me hast son father thine\n",
      "Topic 15: king lord and henri queen gloucest richard york warwick edward\n",
      "Topic 16: antoni caesar cleopatra enobarbu leont camillo charmian th pompey the\n",
      "Topic 17: sir clown tobi gentleman olivia viola malvolio madam countess ladi\n",
      "Topic 18: page ford master falstaff sir mistress ann you host quickli\n",
      "Topic 19: rosalind you falstaff good pistol sir orlando bardolph shallow celia\n"
     ]
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=num_topics, n_iter=num_iter)\n",
    "model.fit(data)\n",
    "\n",
    "topic_word = model.topic_word_\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
